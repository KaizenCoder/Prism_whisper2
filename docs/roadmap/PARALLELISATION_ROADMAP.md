# âš¡ ROADMAP PARALLÃ‰LISATION - Prism_whisper2
## Optimisations Performance : 7-8s â†’ <3s latence

### **ðŸŽ¯ OBJECTIF PERFORMANCE**
- **Latence actuelle** : 7-8 secondes
- **Latence cible** : <3 secondes  
- **Latence optimale** : <1 seconde (stretch goal)

---

## ðŸ“Š **ANALYSE BOTTLENECKS ACTUELS**

### **Profiling Latence Actuelle**
```
Win+Alt+V pressed â†’ [100ms] â†’ Talon detection
    â†“
Trigger file created â†’ [50ms] â†’ Bridge detection  
    â†“
Audio recording â†’ [3000ms] â†’ 3 seconds fixed
    â†“
Model loading â†’ [4000ms] â†’ Whisper model init âš ï¸ BOTTLENECK #1
    â†“
Transcription â†’ [800ms] â†’ GPU processing
    â†“
Clipboard + Paste â†’ [150ms] â†’ Windows integration
    â†“
TOTAL: ~8100ms
```

### **Bottlenecks Critiques IdentifiÃ©s**
1. **ðŸš¨ Model Loading (4s)** : Whisper init Ã  chaque appel
2. **âš ï¸ Fixed Recording (3s)** : Pas de dÃ©tection fin de phrase
3. **ðŸ”„ Sequential Pipeline** : Pas de parallÃ©lisation

---

## ðŸš€ **STRATÃ‰GIES DE PARALLÃ‰LISATION**

### **Phase 1 : Model Pre-loading (Gain: -4s)**

#### **Architecture ProposÃ©e : Background Service**
```python
# Service permanent en arriÃ¨re-plan
class WhisperService:
    def __init__(self):
        self.model = WhisperModel("medium", device="cuda")  # PrÃ©-chargÃ©
        self.queue = asyncio.Queue()
        
    async def start_service(self):
        """Service permanent Ã©coute requests"""
        while True:
            audio_data = await self.queue.get()
            result = await self.transcribe_async(audio_data)
            await self.send_result(result)
```

#### **Communication IPC optimisÃ©e**
- **Named Pipes** au lieu de fichiers
- **Memory mapping** pour audio data
- **Async callbacks** pour rÃ©sultats

#### **ImplÃ©mentation**
```
Process 1: PrismBridge (hotkey detection)
Process 2: WhisperService (modÃ¨le prÃ©-chargÃ© permanent)
Process 3: AudioCapture (recording continu)
```

### **Phase 2 : Smart Audio Capture (Gain: -1.5s)**

#### **VAD (Voice Activity Detection)**
```python
class SmartAudioCapture:
    def __init__(self):
        self.vad = webrtcvad.Vad(3)  # AggressivitÃ© max
        self.buffer = CircularBuffer(5000)  # 5s buffer
        
    async def capture_with_vad(self):
        """Capture jusqu'Ã  dÃ©tection silence"""
        while True:
            chunk = await self.record_chunk(100ms)
            if self.vad.is_speech(chunk):
                self.buffer.add(chunk)
            elif len(self.buffer) > 500ms:  # Fin dÃ©tectÃ©e
                return self.buffer.get_audio()
```

#### **Streaming Audio**
- **Capture continue** en background
- **Trigger dÃ©clenche** processing du buffer
- **Adaptive duration** : 0.5s - 10s selon contenu

### **Phase 3 : Pipeline Async (Gain: -1s)**

#### **Architecture Pipeline**
```python
async def optimized_pipeline():
    # ParallÃ©lisation maximale
    audio_task = asyncio.create_task(capture_audio())
    
    # Pendant capture audio, prÃ©parer transcription
    model_task = asyncio.create_task(prepare_model())
    
    # DÃ¨s audio prÃªt, dÃ©marrer transcription
    audio_data = await audio_task
    transcription_task = asyncio.create_task(
        transcribe_async(audio_data)
    )
    
    # Pendant transcription, prÃ©parer clipboard
    clipboard_task = asyncio.create_task(prepare_clipboard())
    
    # Finaliser
    text = await transcription_task
    await paste_text(text)
```

### **Phase 4 : Hardware Optimizations (Gain: -0.5s)**

#### **GPU Stream Parallel**
```python
# Multiple CUDA streams pour parallÃ©liser
stream1 = torch.cuda.Stream()
stream2 = torch.cuda.Stream()

with torch.cuda.stream(stream1):
    # Pre-processing audio
    audio_tensor = preprocess_audio(raw_audio)
    
with torch.cuda.stream(stream2):
    # Pendant ce temps, prÃ©parer modÃ¨le
    model.prepare_next_inference()
```

#### **Memory Pool Management**
- **Pre-allocated tensors** pour Ã©viter malloc/free
- **Circular buffers** GPU memory
- **Zero-copy** transfers CPUâ†”GPU

---

## ðŸ“‹ **PLAN D'IMPLÃ‰MENTATION**

### **Sprint 1 : Background Service (Week 1)**
**Effort** : 8-12h  
**Gain attendu** : 8s â†’ 4s

#### **Tasks**
- [ ] **Whisper Service Process** : Service permanent + IPC
- [ ] **Bridge Refactor** : Communication async avec service
- [ ] **Process Management** : Auto-restart, healthcheck
- [ ] **Testing** : Validation performance + stabilitÃ©

#### **Code Changes**
```
src/services/whisper_service.py     # Nouveau service
src/bridge/prism_bridge.py          # Refactor communication
src/ipc/named_pipes.py             # Communication optimisÃ©e
tests/test_background_service.py   # Tests performance
```

### **Sprint 2 : Smart Audio (Week 2)**
**Effort** : 6-8h  
**Gain attendu** : 4s â†’ 2.5s

#### **Tasks**
- [ ] **VAD Integration** : webrtcvad ou similar
- [ ] **Adaptive Recording** : Dynamic duration
- [ ] **Audio Buffers** : Circular buffer management
- [ ] **Edge Cases** : Silence handling, noise filtering

### **Sprint 3 : Pipeline Async (Week 3)**
**Effort** : 4-6h  
**Gain attendu** : 2.5s â†’ 1.5s

#### **Tasks**
- [ ] **Async Pipeline** : Refactor sÃ©quentiel â†’ async
- [ ] **Task Management** : asyncio orchestration
- [ ] **Error Handling** : Async error propagation
- [ ] **Performance Monitoring** : Latency tracking

### **Sprint 4 : Hardware Optimization (Week 4)**
**Effort** : 6-10h  
**Gain attendu** : 1.5s â†’ <1s

#### **Tasks**
- [ ] **GPU Streams** : CUDA parallel processing
- [ ] **Memory Optimization** : Pre-allocation, zero-copy
- [ ] **Batch Processing** : Multiple requests handling
- [ ] **Profiling** : GPU utilization optimization

---

## ðŸ“Š **MÃ‰TRIQUES & MONITORING**

### **Performance Tracking**
```python
class PerformanceMonitor:
    def track_latency(self):
        stages = {
            'hotkey_detection': 0,
            'audio_capture': 0,
            'transcription': 0,
            'clipboard_paste': 0,
            'total': 0
        }
        return stages
```

### **Target Metrics Par Sprint**
| Sprint | Latence Cible | Bottleneck Focus | Success Criteria |
|--------|---------------|------------------|------------------|
| 1 | <4s | Model loading | Service starts <200ms |
| 2 | <2.5s | Audio capture | VAD detection <500ms |
| 3 | <1.5s | Pipeline sync | Async overlap 70% |
| 4 | <1s | GPU utilization | GPU usage >80% |

### **Monitoring Dashboard**
- **Real-time latency** : Per-stage timing
- **Resource usage** : CPU, GPU, Memory
- **Error rates** : Failed transcriptions, timeouts
- **User satisfaction** : Perceived responsiveness

---

## ðŸš¨ **RISQUES & MITIGATION**

### **Risques Techniques**
1. **Complexity increase** â†’ Phased rollout, extensive testing
2. **Memory usage spike** â†’ Resource monitoring, limits
3. **Service stability** â†’ Auto-restart, health checks
4. **GPU contention** â†’ Queue management, priority system

### **Fallback Strategy**
- **Graceful degradation** : Si service fails â†’ fallback mode actuel
- **Performance monitoring** : Auto-switch si latence dÃ©gradÃ©e
- **User notification** : Feedback si problÃ¨me dÃ©tectÃ©

---

## ðŸŽ¯ **SUCCESS CRITERIA**

### **MVP OptimisÃ© (End of Sprint 2)**
- **Latence <3s** : Objectif principal atteint
- **Reliability >99%** : Pas de rÃ©gression stabilitÃ©
- **User feedback positive** : Tests utilisateurs

### **Production Ready (End of Sprint 4)**
- **Latence <1s** : Performance optimale
- **Monitoring complet** : Dashboard + alerting
- **Documentation** : Setup, troubleshooting, tuning

---

**ðŸš€ ROADMAP EXECUTION : 4 sprints x 1 semaine = 1 mois pour transformation complÃ¨te performance** 